{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent':\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.134 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://www.timesjobs.com/\", headers=headers)\n",
    "soup = BeautifulSoup(r.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "belong_to_it_li = soup.find('li', class_='top-ind-it wht-shd-bx')\n",
    "href_out_a = str([a_href['href'].split(\"<li>\") for a_href in belong_to_it_li.select('a', href = True)]).strip(\"[\").strip(\"]\").strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.timesjobs.com/candidate/job-search.html?searchType=Home_Search&from=submit&asKey=OFF&txtKeywords=&cboPresFuncArea=35'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "href_out_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_list = []\n",
    "for x in range(1,800):\n",
    "    if x <=1:\n",
    "        all_href = href_out_a\n",
    "    elif x>=2:\n",
    "        all_href = (href_out_a+f\"&pDate=Y&sequence=2&startPage={x}\")\n",
    "    else:\n",
    "        print(\"Good!! You're good\")\n",
    "    get_IT_requ = requests.get(all_href, headers = headers)\n",
    "    it_soup = BeautifulSoup(get_IT_requ.content, 'lxml')\n",
    "\n",
    "    job_title = it_soup.find_all('li', class_='clearfix job-bx wht-shd-bx')\n",
    "\n",
    "    for title in job_title:\n",
    "\n",
    "        three_data = title.find('header', class_='clearfix')\n",
    "        loc_experi = title.find('ul', class_='top-jd-dtl clearfix')\n",
    "        des_skills = title.find('ul', class_='list-job-dtl clearfix')\n",
    "\n",
    "        # Job title\n",
    "        job_name=', '.join([joby.get_text() for joby in three_data.find_all('h2')]).strip()\n",
    "\n",
    "        # Company Name\n",
    "        company_name= ', '.join([com.get_text() for com in three_data.find_all('h3')]).strip()\n",
    "\n",
    "        # Experience\n",
    "        experience = loc_experi.find('li').find(text=True, recursive=False)\n",
    "        if experience is None:\n",
    "            experience = \"Experience Not Mentioned\"\n",
    "        else:\n",
    "            experience = experience\n",
    "\n",
    "        # Location\n",
    "        location = loc_experi.find('span').find(text=True, recursive=False)\n",
    "        if location is None:\n",
    "            location = \"Location Not Found\"\n",
    "        else:\n",
    "            location = location\n",
    "\n",
    "        # Description\n",
    "        des = des_skills.find('li')\n",
    "        des.label.decompose()\n",
    "        description = des.text.strip()\n",
    "\n",
    "        # Key Skills\n",
    "        key_skill = des_skills.find('span', class_='srp-skills').text.strip()\n",
    "\n",
    "        # Job Detail Link\n",
    "        job_detail_link='/ '.join([d_link['href']for d_link in three_data.find_all('a', href = True)]).strip()\n",
    "\n",
    "\n",
    "        all_data_dict = {\n",
    "            'Job Title': job_name,\n",
    "            'Company Name': company_name,\n",
    "            'Experience': experience,\n",
    "            'Location': location,\n",
    "            'Job Description': description,\n",
    "            'Key Skills': key_skill,\n",
    "            'Job Detail Link': job_detail_link\n",
    "        }\n",
    "        all_data_list.append(all_data_dict)\n",
    "        df = pd.DataFrame(all_data_list)\n",
    "df.index = df.index+1\n",
    "df.to_excel('D:\\Programming\\Python Coding\\DcodeTech Projects\\Times Jobs\\Data\\Times_Jobs.xlsx', index_label= 'Sr No.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7df1183e51019eefb7d27cff3876226a0997c79b16df418e8dd6cc274777a51a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
